#!/usr/bin/env python3
"""
Trainerç«¯æµ‹è¯•è„šæœ¬
åŠŸèƒ½ï¼šåˆå§‹åŒ–TensorTableï¼Œåˆ›å»ºæŒ‡å®šæ•°é‡å’Œå¤§å°çš„torch.Tensorï¼Œè°ƒç”¨multi_put
æ”¯æŒå¾ªç¯æµ‹è¯•ä»¥éªŒè¯ç¨³å®šæ€§å’Œæ€§èƒ½
æ·»åŠ MD5æ ¡éªŒåŠŸèƒ½éªŒè¯æ•°æ®ä¼ è¾“æ­£ç¡®æ€§
"""

import torch
import sys
import os
import time
import logging
import argparse
import hashlib
from astate.parallel_config import ParallelConfig
import random

# æ·»åŠ astateå®¢æˆ·ç«¯åº“åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.getcwd(), 'build', 'python'))

try:
    import astate
    from astate import ShardedKey, TensorTableType, TensorStorage
    print("âœ… Successfully imported astate")
except ImportError as e:
    print(f"âŒ Failed to import astate: {e}")
    print("è¯·ç¡®ä¿å·²ç¼–è¯‘Pythonç»‘å®šæ¨¡å—")
    sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO,
                    format='[TRAINER] %(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

from typing import Any

def print_refcount(obj: Any, name: str = "Object") -> None:
    """
    Print the reference count of the given object.
    
    Args:
    obj (Any): The object whose reference count you want to check.
    name (str): A name to identify the object in the output (default: "Object").
    """
    count = sys.getrefcount(obj) - 1  # Subtract 1 to account for the temporary reference
    print(f"Reference count for {name}: {count}")

def calculate_tensor_md5(tensor):
    """è®¡ç®—tensorçš„MD5å€¼"""
    # å°†tensorè½¬æ¢ä¸ºè¿ç»­çš„å­—èŠ‚æµ
    tensor_bytes = tensor.detach().cpu().numpy().tobytes()
    return hashlib.md5(tensor_bytes).hexdigest()


def write_md5_to_file(tensor_data, iteration, seq_id, output_dir="md5_output"):
    """å°†tensorçš„MD5å€¼å†™å…¥æ–‡ä»¶"""
    os.makedirs(output_dir, exist_ok=True)

    md5_filename = os.path.join(
        output_dir, f"train_md5_iter{iteration}_seq{seq_id}.txt")

    logger.info(f"è®¡ç®—å¹¶å†™å…¥MD5å€¼åˆ°æ–‡ä»¶: {md5_filename}")

    with open(md5_filename, 'w') as f:
        f.write(
            f"# Trainer MD5 values - Iteration {iteration}, Seq ID {seq_id}\n")
        f.write(f"# Format: tensor_key,md5_hash,shape,dtype\n")

        for key, tensor in tensor_data:
            md5_hash = calculate_tensor_md5(tensor)
            shape_str = "x".join(map(str, tensor.shape))
            dtype_str = str(tensor.dtype)

            f.write(f"{key.key},{md5_hash},{shape_str},{dtype_str}\n")

    logger.info(f"âœ… MD5å€¼å·²å†™å…¥æ–‡ä»¶: {md5_filename}")
    return md5_filename


def create_test_tensors(num_tensors=100, height=4000, width=500, device='cpu'):
    """åˆ›å»ºæµ‹è¯•ç”¨çš„tensoræ•°æ®"""
    logger.info(f"Creating {num_tensors} tensors of size {height}x{width} on {device}")

    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if device == 'cuda' and not torch.cuda.is_available():
        logger.warning("CUDAä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU")
        device = 'cpu'
    
    # è®¾ç½®è®¾å¤‡
    torch_device = torch.device(device)
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {torch_device}")

    tensor_data = []
    for i in range(num_tensors):
        # åˆ›å»ºéšæœºæ•°æ®tensorï¼ŒæŒ‡å®šè®¾å¤‡
        tensor = torch.randn(height, width, dtype=torch.float32, device=torch_device)

        # åˆ›å»ºShardedKey
        key = ShardedKey()
        key.key = f"tensor_{i:03d}"
        key.globalShape = [height, width]
        key.globalOffset = [0, 0]

        tensor_data.append((key, tensor))

        if (i + 1) % 10 == 0:
            logger.info(f"Created {i + 1} tensors on {device}...")

    logger.info(f"âœ… Created {num_tensors} tensors successfully on {device}")
    return tensor_data


def verify_data_generation(tensor_data):
    """éªŒè¯ç”Ÿæˆçš„æ•°æ®"""
    logger.info("Verifying generated data...")

    non_zero_count = 0
    total_elements = 0

    for key, tensor in tensor_data:
        # è®¡ç®—éé›¶å…ƒç´ æ•°é‡
        non_zero = torch.count_nonzero(tensor).item()
        total = tensor.numel()

        non_zero_count += non_zero
        total_elements += total

        if (key.key == "tensor_000" or key.key == "tensor_099"):  # åªè®°å½•ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ª
            logger.info(f"Tensor {key.key}: {non_zero}/{total} non-zero elements "
                        f"(mean: {tensor.mean().item():.4f}, std: {tensor.std().item():.4f})")

    percentage = (non_zero_count / total_elements) * \
        100 if total_elements > 0 else 0
    logger.info(
        f"Overall: {non_zero_count}/{total_elements} non-zero elements ({percentage:.2f}%)")

    return non_zero_count > 0


def parse_args():
    parser = argparse.ArgumentParser(description="Trainerç«¯æµ‹è¯•è„šæœ¬ - æ”¯æŒå¾ªç¯æµ‹è¯•å’ŒMD5æ ¡éªŒ")
    parser.add_argument("--role_rank", type=int, default=0, help="role rank")
    parser.add_argument("--role_size", type=int, default=1, help="role size")
    parser.add_argument("--iterations", type=int,
                        default=5, help="å¾ªç¯æµ‹è¯•æ¬¡æ•° (é»˜è®¤: 5)")
    parser.add_argument("--sleep", type=int, default=3,
                        help="æ¯æ¬¡å¾ªç¯é—´éš”ç§’æ•° (é»˜è®¤: 3)")
    parser.add_argument("--num_tensors", type=int,
                        default=20, help="tensoræ•°é‡ (é»˜è®¤: 20)")
    parser.add_argument("--height", type=int, default=20000,
                        help="tensoré«˜åº¦ (é»˜è®¤: 20000)")
    parser.add_argument("--width", type=int, default=5000,
                        help="tensorå®½åº¦ (é»˜è®¤: 5000)")
    parser.add_argument("--seq_id", type=int, default=1, help="åºåˆ—ID (é»˜è®¤: 1)")
    parser.add_argument("--output_dir", type=str, default="md5_output",
                        help="MD5è¾“å‡ºç›®å½• (é»˜è®¤: md5_output)")
    parser.add_argument('--md5-check', action='store_true',
                        default=os.getenv(
                            'ASTATE_ENABLE_MD5_CHECK', '1') == '1',
                        help='æ˜¯å¦å¯ç”¨MD5æ ¡éªŒï¼Œé»˜è®¤å¯ç”¨')
    parser.add_argument('--random-sleep-max', type=float, default=float(os.getenv('ASTATE_RANDOM_SLEEP_MAX', 5)),
                        help='æ¯è½®æ¨ç†åæœ€å¤§éšæœºsleepç§’æ•°ï¼Œå¤§äº0å¯ç”¨éšæœºsleepï¼Œé»˜è®¤5')
    parser.add_argument('--device', type=str, default='cpu', choices=['cpu', 'cuda'],
                        help='tensoråˆ›å»ºè®¾å¤‡ (é»˜è®¤: cpu, å¯é€‰: cuda)')
    return parser.parse_args()


def main():
    args = parse_args()
    enable_md5 = args.md5_check
    random_sleep_max = args.random_sleep_max
    logger.info("ğŸš€ Starting Trainer script...")

    try:
        # åˆ›å»ºREMOTEç±»å‹çš„TensorTable
        logger.info("Creating REMOTE TensorTable...")
        parallel_config = ParallelConfig.create_training_config(
            role_size=args.role_size, role_rank=args.role_rank)
        table = astate.create_remote_table(
            "remote_tensor_table", parallel_config)
        logger.info("âœ… TensorTable created")

        # é…ç½®å¾ªç¯å‚æ•°
        num_iterations = args.iterations
        sleep_between_iterations = args.sleep
        seq_id = args.seq_id

        # è®°å½•æ€»ä½“ç»Ÿè®¡
        total_times = []
        complete_times = []
        successful_iterations = 0
        md5_files = []  # è®°å½•ç”Ÿæˆçš„MD5æ–‡ä»¶

        # åœ¨å¾ªç¯å¤–åˆ›å»ºtensorsï¼Œæ‰€æœ‰è¿­ä»£ä½¿ç”¨åŒä¸€æ‰¹tensor
        logger.info(
            f"ğŸ“¦ åˆ›å»ºå…±äº«çš„tensoræ•°æ® (tensors={args.num_tensors}, å°ºå¯¸={args.height}x{args.width}, è®¾å¤‡={args.device})...")
        tensor_data = create_test_tensors(
            num_tensors=args.num_tensors, height=args.height, width=args.width, device=args.device)

        # éªŒè¯ç”Ÿæˆçš„æ•°æ®
        if verify_data_generation(tensor_data):
            logger.info("âœ… æ•°æ®ç”ŸæˆéªŒè¯æˆåŠŸ - åŒ…å«éé›¶æ•°æ®")
        else:
            logger.warning("âš ï¸ æ•°æ®ç”ŸæˆéªŒè¯è­¦å‘Š - æ‰€æœ‰tensorséƒ½ä¸ºé›¶")

        logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œ {num_iterations} æ¬¡ multi_put å¾ªç¯æµ‹è¯•...")
        logger.info(
            f"ğŸ“‹ æµ‹è¯•å‚æ•°: tensors={args.num_tensors}, å°ºå¯¸={args.height}x{args.width}, seq_id={seq_id}")
        logger.info(f"ğŸ’¡ æ³¨æ„: æ‰€æœ‰è¿­ä»£ä½¿ç”¨åŒä¸€æ‰¹tensorå¯¹è±¡")

        for iteration in range(0, num_iterations):
            logger.info(f"\nğŸ”„ === ç¬¬ {iteration}/{num_iterations} æ¬¡è¿­ä»£ ===")

            try:
                # è®¡ç®—å¹¶ä¿å­˜MD5å€¼
                if enable_md5:
                    logger.info(f"[è¿­ä»£{iteration}] è®¡ç®—tensor MD5å€¼...")
                    md5_file = write_md5_to_file(
                        tensor_data, iteration, seq_id + iteration, args.output_dir)
                    md5_files.append(md5_file)

                # æ‰§è¡Œmulti_put
                logger.info(
                    f"[è¿­ä»£{iteration}] è°ƒç”¨ multi_put (seq_id={seq_id})...")

                start_time = time.time()
                # for key, tensor in tensor_data:
                #     print_refcount(tensor, key.key)
                success = table.multi_put(seq_id + iteration, tensor_data)
                # for key, tensor in tensor_data:
                #     print_refcount(tensor, key.key)
                end_time = time.time()

                # è°ƒç”¨complete
                logger.info(f"[è¿­ä»£{iteration}] è°ƒç”¨ complete...")
                complete_start_time = time.time()
                table.complete(seq_id + iteration)
                complete_end_time = time.time()

                iteration_time = end_time - start_time
                total_times.append(iteration_time)

                complete_time = complete_end_time - complete_start_time
                complete_times.append(complete_time)

                if success:
                    logger.info(
                        f"[è¿­ä»£{iteration}] âœ… multi_put æˆåŠŸå®Œæˆï¼Œè€—æ—¶ {iteration_time:.2f} ç§’")
                    logger.info(
                        f"[è¿­ä»£{iteration}] å¹³å‡æ¯ä¸ªtensoræ—¶é—´: {iteration_time/len(tensor_data)*1000:.2f} ms")

                    logger.info(
                        f"[è¿­ä»£{iteration}] âœ… complete æˆåŠŸå®Œæˆï¼Œè€—æ—¶ {complete_time:.2f} ç§’")
                    successful_iterations += 1

                else:
                    logger.error(f"[è¿­ä»£{iteration}] âŒ multi_put å¤±è´¥")

                # åœ¨è¿­ä»£ä¹‹é—´æ·»åŠ å»¶è¿Ÿï¼ˆé™¤äº†æœ€åä¸€æ¬¡ï¼‰
                if iteration < num_iterations:
                    if random_sleep_max > 0 and iteration != num_iterations - 1:
                        sleep_time = random.uniform(0, random_sleep_max)
                        logger.info(f"[éšæœºsleep] æœ¬è½®sleep {sleep_time:.2f} ç§’")
                        time.sleep(sleep_time)
                    else:
                        logger.info(
                            f"[è¿­ä»£{iteration}] ç­‰å¾… {sleep_between_iterations} ç§’åç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£...")
                        time.sleep(sleep_between_iterations)

            except Exception as e:
                logger.error(f"[è¿­ä»£{iteration}] âŒ è¿­ä»£è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

        # è¾“å‡ºæ€»ä½“ç»Ÿè®¡
        logger.info(f"\nğŸ‰ === å¾ªç¯æµ‹è¯•ç»Ÿè®¡ç»“æœ ===")
        logger.info(f"æ€»è¿­ä»£æ¬¡æ•°: {num_iterations}")
        logger.info(f"æˆåŠŸæ¬¡æ•°: {successful_iterations}")
        logger.info(f"æˆåŠŸç‡: {successful_iterations/num_iterations*100:.1f}%")

        if total_times:
            logger.info(
                f"multi_put å¹³å‡è€—æ—¶: {sum(total_times)/len(total_times):.2f} ç§’")
            logger.info(f"multi_put æœ€å¿«è€—æ—¶: {min(total_times):.2f} ç§’")
            logger.info(f"multi_put æœ€æ…¢è€—æ—¶: {max(total_times):.2f} ç§’")
            logger.info(f"multi_put æ€»è€—æ—¶: {sum(total_times):.2f} ç§’")

        if complete_times:
            logger.info(
                f"complete å¹³å‡è€—æ—¶: {sum(complete_times)/len(complete_times):.2f} ç§’")
            logger.info(f"complete æœ€å¿«è€—æ—¶: {min(complete_times):.2f} ç§’")
            logger.info(f"complete æœ€æ…¢è€—æ—¶: {max(complete_times):.2f} ç§’")
            logger.info(f"complete æ€»è€—æ—¶: {sum(complete_times):.2f} ç§’")

        if total_times:
            # è®¡ç®—ååé‡ç»Ÿè®¡
            avg_time = sum(total_times) / len(total_times)
            tensors_per_sec = args.num_tensors / avg_time
            mb_per_sec = (args.num_tensors * args.height *
                          # å‡è®¾float32
                          args.width * 4) / (1024 * 1024) / avg_time

            logger.info(f"å¹³å‡ååé‡: {tensors_per_sec:.1f} tensors/ç§’")
            logger.info(f"å¹³å‡æ•°æ®ååé‡: {mb_per_sec:.1f} MB/ç§’")

        # è¾“å‡ºMD5æ–‡ä»¶ä¿¡æ¯
        logger.info(f"\nğŸ“ === MD5æ–‡ä»¶ä¿¡æ¯ ===")
        logger.info(f"ç”Ÿæˆçš„MD5æ–‡ä»¶æ•°é‡: {len(md5_files)}")
        for md5_file in md5_files:
            logger.info(f"MD5æ–‡ä»¶: {md5_file}")

        if successful_iterations == num_iterations:
            logger.info("ğŸ‰ æ‰€æœ‰è¿­ä»£éƒ½æˆåŠŸå®Œæˆï¼Trainer script æµ‹è¯•é€šè¿‡ï¼")
            return 0
        elif successful_iterations > 0:
            logger.warning(
                f"âš ï¸ éƒ¨åˆ†è¿­ä»£æˆåŠŸï¼Œ{num_iterations - successful_iterations} æ¬¡å¤±è´¥")
            return 1
        else:
            logger.error("âŒ æ‰€æœ‰è¿­ä»£éƒ½å¤±è´¥äº†")
            return 1

    except Exception as e:
        logger.error(f"âŒ Trainer script å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
